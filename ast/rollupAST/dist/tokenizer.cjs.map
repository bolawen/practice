{"version":3,"sources":["../src/tokenizer.ts","../src/utils.ts"],"sourcesContent":["import { isWhiteSpace, isAlpha, isDigit, isUnderline } from \"./utils\";\n\nexport enum TokenType {\n  Let = \"Let\",\n  Const = \"Const\",\n  Var = \"Var\",\n  Assign = \"Assign\",\n  Function = \"Function\",\n  Number = \"Number\",\n  Operator = \"Operator\",\n  Identifier = \"Identifier\",\n  LeftParen = \"LeftParen\",\n  RightParen = \"RightParen\",\n  LeftCurly = \"LeftCurly\",\n  RightCurly = \"RightCurly\",\n  Comma = \"Comma\",\n  Dot = \"Dot\",\n  Semicolon = \"Semicolon\",\n  StringLiteral = \"StringLiteral\",\n  Return = \"Return\",\n  Import = \"Import\",\n  Export = \"Export\",\n  Default = \"Default\",\n  From = \"From\",\n  As = \"As\",\n  Asterisk = \"Asterisk\",\n}\n\nexport enum ScanMode {\n  Normal,\n  Identifier,\n  StringLiteral,\n  Number,\n}\n\nexport type Token = {\n  type: TokenType;\n  value?: string;\n  start: number;\n  end: number;\n  raw?: string;\n};\n\n// 策略模式\nconst TOKENS_GENERATOR: Record<string, (...args: any[]) => Token> = {\n  let(start: number) {\n    return { type: TokenType.Let, value: \"let\", start, end: start + 3 };\n  },\n  const(start: number) {\n    return { type: TokenType.Const, value: \"const\", start, end: start + 5 };\n  },\n  var(start: number) {\n    return { type: TokenType.Var, value: \"var\", start, end: start + 3 };\n  },\n  assign(start: number) {\n    return { type: TokenType.Assign, value: \"=\", start, end: start + 1 };\n  },\n  import(start: number) {\n    return {\n      type: TokenType.Import,\n      value: \"import\",\n      start,\n      end: start + 6,\n    };\n  },\n  export(start: number) {\n    return {\n      type: TokenType.Export,\n      value: \"export\",\n      start,\n      end: start + 6,\n    };\n  },\n  from(start: number) {\n    return {\n      type: TokenType.From,\n      value: \"from\",\n      start,\n      end: start + 4,\n    };\n  },\n  as(start: number) {\n    return {\n      type: TokenType.As,\n      value: \"as\",\n      start,\n      end: start + 2,\n    };\n  },\n  asterisk(start: number) {\n    return {\n      type: TokenType.Asterisk,\n      value: \"*\",\n      start,\n      end: start + 1,\n    };\n  },\n  default(start: number) {\n    return {\n      type: TokenType.Default,\n      value: \"default\",\n      start,\n      end: start + 7,\n    };\n  },\n  number(start: number, value: string) {\n    return {\n      type: TokenType.Number,\n      value,\n      start,\n      end: start + value.length,\n      raw: value,\n    };\n  },\n  function(start: number) {\n    return {\n      type: TokenType.Function,\n      value: \"function\",\n      start,\n      end: start + 8,\n    };\n  },\n  return(start: number) {\n    return {\n      type: TokenType.Return,\n      value: \"return\",\n      start,\n      end: start + 6,\n    };\n  },\n  operator(start: number, value: string) {\n    return {\n      type: TokenType.Operator,\n      value,\n      start,\n      end: start + value.length,\n    };\n  },\n  comma(start: number) {\n    return {\n      type: TokenType.Comma,\n      value: \",\",\n      start,\n      end: start + 1,\n    };\n  },\n  leftParen(start: number) {\n    return { type: TokenType.LeftParen, value: \"(\", start, end: start + 1 };\n  },\n  rightParen(start: number) {\n    return { type: TokenType.RightParen, value: \")\", start, end: start + 1 };\n  },\n  leftCurly(start: number) {\n    return { type: TokenType.LeftCurly, value: \"{\", start, end: start + 1 };\n  },\n  rightCurly(start: number) {\n    return { type: TokenType.RightCurly, value: \"}\", start, end: start + 1 };\n  },\n  dot(start: number) {\n    return { type: TokenType.Dot, value: \".\", start, end: start + 1 };\n  },\n  semicolon(start: number) {\n    return { type: TokenType.Semicolon, value: \";\", start, end: start + 1 };\n  },\n  stringLiteral(start: number, value: string, raw: string) {\n    return {\n      type: TokenType.StringLiteral,\n      value,\n      start,\n      end: start + value.length + 2,\n      raw,\n    };\n  },\n  identifier(start: number, value: string) {\n    return {\n      type: TokenType.Identifier,\n      value,\n      start,\n      end: start + value.length,\n    };\n  },\n};\n\ntype SingleCharTokens = \"(\" | \")\" | \"{\" | \"}\" | \".\" | \";\" | \",\" | \"*\" | \"=\";\n\nconst KNOWN_SINGLE_CHAR_TOKENS = new Map<\n  SingleCharTokens,\n  typeof TOKENS_GENERATOR[keyof typeof TOKENS_GENERATOR]\n>([\n  [\"(\", TOKENS_GENERATOR.leftParen],\n  [\")\", TOKENS_GENERATOR.rightParen],\n  [\"{\", TOKENS_GENERATOR.leftCurly],\n  [\"}\", TOKENS_GENERATOR.rightCurly],\n  [\".\", TOKENS_GENERATOR.dot],\n  [\";\", TOKENS_GENERATOR.semicolon],\n  [\",\", TOKENS_GENERATOR.comma],\n  [\"*\", TOKENS_GENERATOR.asterisk],\n  [\"=\", TOKENS_GENERATOR.assign],\n]);\n\nconst QUOTATION_TOKENS = [\"'\", '\"', \"`\"];\n\nconst OPERATOR_TOKENS = [\n  \"+\",\n  \"-\",\n  \"*\",\n  \"/\",\n  \"%\",\n  \"^\",\n  \"&\",\n  \"|\",\n  \"~\",\n  \"<<\",\n  \">>\",\n];\n\nexport class Tokenizer {\n  private _tokens: Token[] = [];\n  private _currentIndex: number = 0;\n  private _source: string;\n  private _scanMode = ScanMode.Normal;\n  constructor(input: string) {\n    this._source = input;\n  }\n\n  scanIndentifier(): void {\n    this._setScanMode(ScanMode.Identifier);\n    // 继续扫描，直到收集完整的单词\n    let identifier = \"\";\n    let currentChar = this._getCurrentChar();\n    const startIndex = this._currentIndex;\n    while (\n      isAlpha(currentChar) ||\n      isDigit(currentChar) ||\n      isUnderline(currentChar)\n    ) {\n      identifier += currentChar;\n      this._currentIndex++;\n      currentChar = this._getCurrentChar();\n    }\n    let token;\n    // 1. 结果为关键字\n    if (identifier in TOKENS_GENERATOR) {\n      token =\n        TOKENS_GENERATOR[identifier as keyof typeof TOKENS_GENERATOR](\n          startIndex\n        );\n    }\n    // 2. 结果为标识符\n    else {\n      token = TOKENS_GENERATOR[\"identifier\"](startIndex, identifier);\n    }\n    this._tokens.push(token);\n    this._resetScanMode();\n  }\n\n  scanStringLiteral(): void {\n    this._setScanMode(ScanMode.StringLiteral);\n    const startIndex = this._currentIndex;\n    let currentChar = this._getCurrentChar();\n    // 记录引号\n    const startQuotation = currentChar;\n    // 继续找字符串\n    this._currentIndex++;\n    let str = \"\";\n    currentChar = this._getCurrentChar();\n    while (currentChar && currentChar !== startQuotation) {\n      str += currentChar;\n      this._currentIndex++;\n      currentChar = this._getCurrentChar();\n    }\n    const token = TOKENS_GENERATOR.stringLiteral(\n      startIndex,\n      str,\n      `${startQuotation}${str}${startQuotation}`\n    );\n    this._tokens.push(token);\n    this._resetScanMode();\n  }\n\n  _scanNumber(): void {\n    this._setScanMode(ScanMode.Number);\n    const startIndex = this._currentIndex;\n    let number = \"\";\n    let currentChar = this._getCurrentChar();\n    let isFloat = false;\n    // 如果是数字，则继续扫描\n    // 需要考虑到小数点\n    while (isDigit(currentChar) || (currentChar === \".\" && !isFloat)) {\n      if (currentChar === \".\") {\n        isFloat = true;\n      }\n      number += currentChar;\n      this._currentIndex++;\n      currentChar = this._getCurrentChar();\n    }\n    if (isFloat && currentChar === \".\") {\n      throw new Error('Unexpected character \".\"');\n    }\n    const token = TOKENS_GENERATOR.number(startIndex, number);\n    this._tokens.push(token);\n    this._resetScanMode();\n  }\n\n  tokenize(): Token[] {\n    // 扫描\n    while (this._currentIndex < this._source.length) {\n      let currentChar = this._source[this._currentIndex];\n      const startIndex = this._currentIndex;\n      // 1. 判断是否是分隔符\n      if (isWhiteSpace(currentChar)) {\n        this._currentIndex++;\n        continue;\n      }\n      // 2. 判断是否是字母\n      else if (isAlpha(currentChar)) {\n        this.scanIndentifier();\n        continue;\n      }\n      // 3. 判断是否是单字符 () {} . ; *\n      else if (KNOWN_SINGLE_CHAR_TOKENS.has(currentChar as SingleCharTokens)) {\n        // * 字符特殊处理\n        if (currentChar === \"*\") {\n          // 前瞻，如果是非 import/export，则认为是二元运算符，避免误判\n          const previousToken = this._getPreviousToken();\n          if (\n            previousToken.type !== TokenType.Import &&\n            previousToken.type !== TokenType.Export\n          ) {\n            this._tokens.push(\n              TOKENS_GENERATOR.operator(startIndex, currentChar)\n            );\n            this._currentIndex++;\n            continue;\n          }\n          // 否则按照 import/export 中的 * 处理\n        }\n        const token = KNOWN_SINGLE_CHAR_TOKENS.get(\n          currentChar as SingleCharTokens\n        )!(startIndex);\n        this._tokens.push(token);\n        this._currentIndex++;\n      }\n      // 4. 判断是否为引号\n      else if (QUOTATION_TOKENS.includes(currentChar)) {\n        this.scanStringLiteral();\n        // 跳过结尾的引号\n        this._currentIndex++;\n        continue;\n      }\n      // 5. 判断二元计算符\n      else if (\n        OPERATOR_TOKENS.includes(currentChar) &&\n        this._scanMode === ScanMode.Normal\n      ) {\n        this._tokens.push(TOKENS_GENERATOR.operator(startIndex, currentChar));\n        this._currentIndex++;\n        continue;\n      } else if (\n        OPERATOR_TOKENS.includes(currentChar + this._getNextChar()) &&\n        this._scanMode === ScanMode.Normal\n      ) {\n        this._tokens.push(\n          TOKENS_GENERATOR.operator(\n            startIndex,\n            currentChar + this._getNextChar()\n          )\n        );\n        this._currentIndex += 2;\n        continue;\n      }\n      // 6. 判断数字\n      else if (isDigit(currentChar)) {\n        this._scanNumber();\n        continue;\n      }\n    }\n    this._resetCurrentIndex();\n    return this._getTokens();\n  }\n\n  private _getCurrentChar() {\n    return this._source[this._currentIndex];\n  }\n\n  private _getNextChar() {\n    if (this._currentIndex + 1 < this._source.length) {\n      return this._source[this._currentIndex + 1];\n    }\n    return \"\";\n  }\n\n  private _resetCurrentIndex() {\n    this._currentIndex = 0;\n  }\n\n  private _getTokens() {\n    return this._tokens;\n  }\n\n  private _getPreviousToken() {\n    // 前瞻 Token\n    if (this._tokens.length > 0) {\n      return this._tokens[this._tokens.length - 1];\n    }\n    throw new Error(\"Previous token not found\");\n  }\n\n  private _setScanMode(mode: ScanMode) {\n    this._scanMode = mode;\n  }\n\n  private _resetScanMode() {\n    this._scanMode = ScanMode.Normal;\n  }\n}\n","// 分隔符\nexport function isWhiteSpace(char: string): boolean {\n  return char === \" \" || char === \"\\t\" || char === \"\\n\" || char === \"\\r\";\n}\n\n// 字母\nexport function isAlpha(char: string): boolean {\n  return (char >= \"a\" && char <= \"z\") || (char >= \"A\" && char <= \"Z\");\n}\n\n// 数字\nexport function isDigit(char: string): boolean {\n  return char >= \"0\" && char <= \"9\";\n}\n\n// 下划线\nexport function isUnderline(char: string): boolean {\n  return char === \"_\";\n}\n"],"mappings":";;;;;;;;;;;;;;;;;;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;;ACCO,SAAS,aAAa,MAAuB;AAClD,SAAO,SAAS,OAAO,SAAS,OAAQ,SAAS,QAAQ,SAAS;AACpE;AAGO,SAAS,QAAQ,MAAuB;AAC7C,SAAQ,QAAQ,OAAO,QAAQ,OAAS,QAAQ,OAAO,QAAQ;AACjE;AAGO,SAAS,QAAQ,MAAuB;AAC7C,SAAO,QAAQ,OAAO,QAAQ;AAChC;AAGO,SAAS,YAAY,MAAuB;AACjD,SAAO,SAAS;AAClB;;;ADhBO,IAAK,YAAL,kBAAKA,eAAL;AACL,EAAAA,WAAA,SAAM;AACN,EAAAA,WAAA,WAAQ;AACR,EAAAA,WAAA,SAAM;AACN,EAAAA,WAAA,YAAS;AACT,EAAAA,WAAA,cAAW;AACX,EAAAA,WAAA,YAAS;AACT,EAAAA,WAAA,cAAW;AACX,EAAAA,WAAA,gBAAa;AACb,EAAAA,WAAA,eAAY;AACZ,EAAAA,WAAA,gBAAa;AACb,EAAAA,WAAA,eAAY;AACZ,EAAAA,WAAA,gBAAa;AACb,EAAAA,WAAA,WAAQ;AACR,EAAAA,WAAA,SAAM;AACN,EAAAA,WAAA,eAAY;AACZ,EAAAA,WAAA,mBAAgB;AAChB,EAAAA,WAAA,YAAS;AACT,EAAAA,WAAA,YAAS;AACT,EAAAA,WAAA,YAAS;AACT,EAAAA,WAAA,aAAU;AACV,EAAAA,WAAA,UAAO;AACP,EAAAA,WAAA,QAAK;AACL,EAAAA,WAAA,cAAW;AAvBD,SAAAA;AAAA,GAAA;AA0BL,IAAK,WAAL,kBAAKC,cAAL;AACL,EAAAA,oBAAA;AACA,EAAAA,oBAAA;AACA,EAAAA,oBAAA;AACA,EAAAA,oBAAA;AAJU,SAAAA;AAAA,GAAA;AAgBZ,IAAM,mBAA8D;AAAA,EAClE,IAAI,OAAe;AACjB,WAAO,EAAE,MAAM,iBAAe,OAAO,OAAO,OAAO,KAAK,QAAQ,EAAE;AAAA,EACpE;AAAA,EACA,MAAM,OAAe;AACnB,WAAO,EAAE,MAAM,qBAAiB,OAAO,SAAS,OAAO,KAAK,QAAQ,EAAE;AAAA,EACxE;AAAA,EACA,IAAI,OAAe;AACjB,WAAO,EAAE,MAAM,iBAAe,OAAO,OAAO,OAAO,KAAK,QAAQ,EAAE;AAAA,EACpE;AAAA,EACA,OAAO,OAAe;AACpB,WAAO,EAAE,MAAM,uBAAkB,OAAO,KAAK,OAAO,KAAK,QAAQ,EAAE;AAAA,EACrE;AAAA,EACA,OAAO,OAAe;AACpB,WAAO;AAAA,MACL,MAAM;AAAA,MACN,OAAO;AAAA,MACP;AAAA,MACA,KAAK,QAAQ;AAAA,IACf;AAAA,EACF;AAAA,EACA,OAAO,OAAe;AACpB,WAAO;AAAA,MACL,MAAM;AAAA,MACN,OAAO;AAAA,MACP;AAAA,MACA,KAAK,QAAQ;AAAA,IACf;AAAA,EACF;AAAA,EACA,KAAK,OAAe;AAClB,WAAO;AAAA,MACL,MAAM;AAAA,MACN,OAAO;AAAA,MACP;AAAA,MACA,KAAK,QAAQ;AAAA,IACf;AAAA,EACF;AAAA,EACA,GAAG,OAAe;AAChB,WAAO;AAAA,MACL,MAAM;AAAA,MACN,OAAO;AAAA,MACP;AAAA,MACA,KAAK,QAAQ;AAAA,IACf;AAAA,EACF;AAAA,EACA,SAAS,OAAe;AACtB,WAAO;AAAA,MACL,MAAM;AAAA,MACN,OAAO;AAAA,MACP;AAAA,MACA,KAAK,QAAQ;AAAA,IACf;AAAA,EACF;AAAA,EACA,QAAQ,OAAe;AACrB,WAAO;AAAA,MACL,MAAM;AAAA,MACN,OAAO;AAAA,MACP;AAAA,MACA,KAAK,QAAQ;AAAA,IACf;AAAA,EACF;AAAA,EACA,OAAO,OAAe,OAAe;AACnC,WAAO;AAAA,MACL,MAAM;AAAA,MACN;AAAA,MACA;AAAA,MACA,KAAK,QAAQ,MAAM;AAAA,MACnB,KAAK;AAAA,IACP;AAAA,EACF;AAAA,EACA,SAAS,OAAe;AACtB,WAAO;AAAA,MACL,MAAM;AAAA,MACN,OAAO;AAAA,MACP;AAAA,MACA,KAAK,QAAQ;AAAA,IACf;AAAA,EACF;AAAA,EACA,OAAO,OAAe;AACpB,WAAO;AAAA,MACL,MAAM;AAAA,MACN,OAAO;AAAA,MACP;AAAA,MACA,KAAK,QAAQ;AAAA,IACf;AAAA,EACF;AAAA,EACA,SAAS,OAAe,OAAe;AACrC,WAAO;AAAA,MACL,MAAM;AAAA,MACN;AAAA,MACA;AAAA,MACA,KAAK,QAAQ,MAAM;AAAA,IACrB;AAAA,EACF;AAAA,EACA,MAAM,OAAe;AACnB,WAAO;AAAA,MACL,MAAM;AAAA,MACN,OAAO;AAAA,MACP;AAAA,MACA,KAAK,QAAQ;AAAA,IACf;AAAA,EACF;AAAA,EACA,UAAU,OAAe;AACvB,WAAO,EAAE,MAAM,6BAAqB,OAAO,KAAK,OAAO,KAAK,QAAQ,EAAE;AAAA,EACxE;AAAA,EACA,WAAW,OAAe;AACxB,WAAO,EAAE,MAAM,+BAAsB,OAAO,KAAK,OAAO,KAAK,QAAQ,EAAE;AAAA,EACzE;AAAA,EACA,UAAU,OAAe;AACvB,WAAO,EAAE,MAAM,6BAAqB,OAAO,KAAK,OAAO,KAAK,QAAQ,EAAE;AAAA,EACxE;AAAA,EACA,WAAW,OAAe;AACxB,WAAO,EAAE,MAAM,+BAAsB,OAAO,KAAK,OAAO,KAAK,QAAQ,EAAE;AAAA,EACzE;AAAA,EACA,IAAI,OAAe;AACjB,WAAO,EAAE,MAAM,iBAAe,OAAO,KAAK,OAAO,KAAK,QAAQ,EAAE;AAAA,EAClE;AAAA,EACA,UAAU,OAAe;AACvB,WAAO,EAAE,MAAM,6BAAqB,OAAO,KAAK,OAAO,KAAK,QAAQ,EAAE;AAAA,EACxE;AAAA,EACA,cAAc,OAAe,OAAe,KAAa;AACvD,WAAO;AAAA,MACL,MAAM;AAAA,MACN;AAAA,MACA;AAAA,MACA,KAAK,QAAQ,MAAM,SAAS;AAAA,MAC5B;AAAA,IACF;AAAA,EACF;AAAA,EACA,WAAW,OAAe,OAAe;AACvC,WAAO;AAAA,MACL,MAAM;AAAA,MACN;AAAA,MACA;AAAA,MACA,KAAK,QAAQ,MAAM;AAAA,IACrB;AAAA,EACF;AACF;AAIA,IAAM,2BAA2B,oBAAI,IAGnC;AAAA,EACA,CAAC,KAAK,iBAAiB,SAAS;AAAA,EAChC,CAAC,KAAK,iBAAiB,UAAU;AAAA,EACjC,CAAC,KAAK,iBAAiB,SAAS;AAAA,EAChC,CAAC,KAAK,iBAAiB,UAAU;AAAA,EACjC,CAAC,KAAK,iBAAiB,GAAG;AAAA,EAC1B,CAAC,KAAK,iBAAiB,SAAS;AAAA,EAChC,CAAC,KAAK,iBAAiB,KAAK;AAAA,EAC5B,CAAC,KAAK,iBAAiB,QAAQ;AAAA,EAC/B,CAAC,KAAK,iBAAiB,MAAM;AAC/B,CAAC;AAED,IAAM,mBAAmB,CAAC,KAAK,KAAK,GAAG;AAEvC,IAAM,kBAAkB;AAAA,EACtB;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AACF;AAEO,IAAM,YAAN,MAAgB;AAAA,EAKrB,YAAY,OAAe;AAJ3B,SAAQ,UAAmB,CAAC;AAC5B,SAAQ,gBAAwB;AAEhC,SAAQ,YAAY;AAElB,SAAK,UAAU;AAAA,EACjB;AAAA,EAEA,kBAAwB;AACtB,SAAK,aAAa,kBAAmB;AAErC,QAAI,aAAa;AACjB,QAAI,cAAc,KAAK,gBAAgB;AACvC,UAAM,aAAa,KAAK;AACxB,WACE,QAAQ,WAAW,KACnB,QAAQ,WAAW,KACnB,YAAY,WAAW,GACvB;AACA,oBAAc;AACd,WAAK;AACL,oBAAc,KAAK,gBAAgB;AAAA,IACrC;AACA,QAAI;AAEJ,QAAI,cAAc,kBAAkB;AAClC,cACE,iBAAiB,UAA2C;AAAA,QAC1D;AAAA,MACF;AAAA,IACJ,OAEK;AACH,cAAQ,iBAAiB,YAAY,EAAE,YAAY,UAAU;AAAA,IAC/D;AACA,SAAK,QAAQ,KAAK,KAAK;AACvB,SAAK,eAAe;AAAA,EACtB;AAAA,EAEA,oBAA0B;AACxB,SAAK,aAAa,qBAAsB;AACxC,UAAM,aAAa,KAAK;AACxB,QAAI,cAAc,KAAK,gBAAgB;AAEvC,UAAM,iBAAiB;AAEvB,SAAK;AACL,QAAI,MAAM;AACV,kBAAc,KAAK,gBAAgB;AACnC,WAAO,eAAe,gBAAgB,gBAAgB;AACpD,aAAO;AACP,WAAK;AACL,oBAAc,KAAK,gBAAgB;AAAA,IACrC;AACA,UAAM,QAAQ,iBAAiB;AAAA,MAC7B;AAAA,MACA;AAAA,MACA,GAAG,cAAc,GAAG,GAAG,GAAG,cAAc;AAAA,IAC1C;AACA,SAAK,QAAQ,KAAK,KAAK;AACvB,SAAK,eAAe;AAAA,EACtB;AAAA,EAEA,cAAoB;AAClB,SAAK,aAAa,cAAe;AACjC,UAAM,aAAa,KAAK;AACxB,QAAI,SAAS;AACb,QAAI,cAAc,KAAK,gBAAgB;AACvC,QAAI,UAAU;AAGd,WAAO,QAAQ,WAAW,KAAM,gBAAgB,OAAO,CAAC,SAAU;AAChE,UAAI,gBAAgB,KAAK;AACvB,kBAAU;AAAA,MACZ;AACA,gBAAU;AACV,WAAK;AACL,oBAAc,KAAK,gBAAgB;AAAA,IACrC;AACA,QAAI,WAAW,gBAAgB,KAAK;AAClC,YAAM,IAAI,MAAM,0BAA0B;AAAA,IAC5C;AACA,UAAM,QAAQ,iBAAiB,OAAO,YAAY,MAAM;AACxD,SAAK,QAAQ,KAAK,KAAK;AACvB,SAAK,eAAe;AAAA,EACtB;AAAA,EAEA,WAAoB;AAElB,WAAO,KAAK,gBAAgB,KAAK,QAAQ,QAAQ;AAC/C,UAAI,cAAc,KAAK,QAAQ,KAAK,aAAa;AACjD,YAAM,aAAa,KAAK;AAExB,UAAI,aAAa,WAAW,GAAG;AAC7B,aAAK;AACL;AAAA,MACF,WAES,QAAQ,WAAW,GAAG;AAC7B,aAAK,gBAAgB;AACrB;AAAA,MACF,WAES,yBAAyB,IAAI,WAA+B,GAAG;AAEtE,YAAI,gBAAgB,KAAK;AAEvB,gBAAM,gBAAgB,KAAK,kBAAkB;AAC7C,cACE,cAAc,SAAS,yBACvB,cAAc,SAAS,uBACvB;AACA,iBAAK,QAAQ;AAAA,cACX,iBAAiB,SAAS,YAAY,WAAW;AAAA,YACnD;AACA,iBAAK;AACL;AAAA,UACF;AAAA,QAEF;AACA,cAAM,QAAQ,yBAAyB;AAAA,UACrC;AAAA,QACF,EAAG,UAAU;AACb,aAAK,QAAQ,KAAK,KAAK;AACvB,aAAK;AAAA,MACP,WAES,iBAAiB,SAAS,WAAW,GAAG;AAC/C,aAAK,kBAAkB;AAEvB,aAAK;AACL;AAAA,MACF,WAGE,gBAAgB,SAAS,WAAW,KACpC,KAAK,cAAc,gBACnB;AACA,aAAK,QAAQ,KAAK,iBAAiB,SAAS,YAAY,WAAW,CAAC;AACpE,aAAK;AACL;AAAA,MACF,WACE,gBAAgB,SAAS,cAAc,KAAK,aAAa,CAAC,KAC1D,KAAK,cAAc,gBACnB;AACA,aAAK,QAAQ;AAAA,UACX,iBAAiB;AAAA,YACf;AAAA,YACA,cAAc,KAAK,aAAa;AAAA,UAClC;AAAA,QACF;AACA,aAAK,iBAAiB;AACtB;AAAA,MACF,WAES,QAAQ,WAAW,GAAG;AAC7B,aAAK,YAAY;AACjB;AAAA,MACF;AAAA,IACF;AACA,SAAK,mBAAmB;AACxB,WAAO,KAAK,WAAW;AAAA,EACzB;AAAA,EAEQ,kBAAkB;AACxB,WAAO,KAAK,QAAQ,KAAK,aAAa;AAAA,EACxC;AAAA,EAEQ,eAAe;AACrB,QAAI,KAAK,gBAAgB,IAAI,KAAK,QAAQ,QAAQ;AAChD,aAAO,KAAK,QAAQ,KAAK,gBAAgB,CAAC;AAAA,IAC5C;AACA,WAAO;AAAA,EACT;AAAA,EAEQ,qBAAqB;AAC3B,SAAK,gBAAgB;AAAA,EACvB;AAAA,EAEQ,aAAa;AACnB,WAAO,KAAK;AAAA,EACd;AAAA,EAEQ,oBAAoB;AAE1B,QAAI,KAAK,QAAQ,SAAS,GAAG;AAC3B,aAAO,KAAK,QAAQ,KAAK,QAAQ,SAAS,CAAC;AAAA,IAC7C;AACA,UAAM,IAAI,MAAM,0BAA0B;AAAA,EAC5C;AAAA,EAEQ,aAAa,MAAgB;AACnC,SAAK,YAAY;AAAA,EACnB;AAAA,EAEQ,iBAAiB;AACvB,SAAK,YAAY;AAAA,EACnB;AACF;","names":["TokenType","ScanMode"]}